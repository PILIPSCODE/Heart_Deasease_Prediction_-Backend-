{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fe8d96d",
   "metadata": {},
   "source": [
    "## Import All Module And Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb90f29",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.14.0)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"d:/tfx/Tugas_Apsi dan SC/.venv/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, learning_curve,  cross_val_score,GridSearchCV\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb4de98",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87791e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    \"age\",        # usia\n",
    "    \"sex\",        # 1 = pria, 0 = wanita\n",
    "    \"cp\",         # chest pain type (1‚Äì4) 1: \"typical angina\", 2: \"atypical angina\", 3: \"non-anginal pain\", 4: \"asymptomatic\"\n",
    "    \"trestbps\",   # resting blood pressure\n",
    "    \"chol\",       # serum cholesterol (mg/dl)\n",
    "    \"fbs\",        # fasting blood sugar > 120 mg/dl 1 = yes, 0 = no\n",
    "    \"restecg\",    # resting electrocardiographic results  0: \"normal\", 1: \"ST-T abnormality\", 2: \"LV hypertrophy\",\n",
    "    \"thalach\",    # maximum heart rate achieved\n",
    "    \"exang\",      # exercise induced angina 1: \"yes\", 0: \"no\",\n",
    "    \"oldpeak\",    # ST depression induced by exercise\n",
    "    \"slope\",      # slope of the peak exercise ST segment 1: \"upsloping\", 2: \"flat\", 3: \"downsloping\"\n",
    "    \"ca\",         # number of major vessels (0‚Äì3) colored by fluoroscopy\n",
    "    \"thal\",       # 3 = normal, 6 = fixed defect, 7 = reversable defect\n",
    "    \"target\"      # diagnosis of heart disease (0 = no, 1‚Äì4 = yes)\n",
    "]\n",
    "\n",
    "numerical_col = [\"age\",\"trestbps\", \"chol\", \"thalach\", \"oldpeak\", \"ca\"]\n",
    "categorical_col = [ \"sex\", \"cp\", \"fbs\", \"restecg\", \"exang\", \"slope\", \"thal\",\"target\",\"region\"]\n",
    "\n",
    "df_cland = pd.read_csv(\"./heart_disease/processed.cleveland.data\", header=None, names=columns)\n",
    "df_cland[\"region\"] = \"Cleveland\"\n",
    "\n",
    "df_hrian = pd.read_csv(\"./heart_disease/reprocessed.hungarian.data\", header=None, names=columns)\n",
    "df_hrian[\"region\"] = \"Hungarian\"\n",
    "\n",
    "df_swit = pd.read_csv(\"./heart_disease/processed.switzerland.data\", header=None, names=columns)\n",
    "df_swit[\"region\"] = \"Switzerland\"\n",
    "\n",
    "df_va = pd.read_csv(\"./heart_disease/processed.va.data\", header=None, names=columns)\n",
    "df_va[\"region\"] = \"Va\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47e91e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_cland, df_hrian, df_swit, df_va], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65803bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5334fb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17cbd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25904360",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ff857a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace(\"?\",np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cb6e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ef00d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace(\"?\", np.nan, inplace=True)\n",
    "df[numerical_col] = df[numerical_col].apply(pd.to_numeric, errors='coerce')\n",
    "df[categorical_col] = df[categorical_col].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55387fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956ab96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf98b709",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    \"sex\": {1: \"male\", 0: \"female\"},\n",
    "    \"cp\": {1: \"typical angina\", 2: \"atypical angina\", 3: \"non-anginal pain\", 4: \"asymptomatic\"},\n",
    "    \"fbs\": {1: \"true\", 0: \"false\", \"1\":\"true\", \"0\":\"false\"},\n",
    "    \"restecg\": {0: \"normal\", 1: \"ST-T abnormality\", 2: \"LV hypertrophy\"},\n",
    "    \"exang\": {1: \"yes\", 0: \"no\", \"1\":\"yes\", \"0\":\"no\"},\n",
    "    \"slope\": {1: \"upsloping\", 2: \"flat\", 3: \"downsloping\", \"1\": \"upsloping\", \"2\": \"flat\", \"3\": \"downsloping\"},\n",
    "    \"thal\": {3: \"normal\", 6: \"fixed defect\", 7: \"reversible defect\", \"3.0\":\"normal\",\"6.0\":\"fixed defect\", \"7.0\":\"reversible defect\", \"3\":\"normal\",\"6\":\"fixed defect\", \"7\":\"reversible defect\"},\n",
    "    \"target\":{0: \"0\", 1:\"1\",2:\"1\", 3:\"1\", 4:\"1\"}\n",
    "}\n",
    "\n",
    "df.replace(mapping, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ada4cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1477f0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe317e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef972f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5e355c",
   "metadata": {},
   "source": [
    "## EDA Explanatory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ec1f0e",
   "metadata": {},
   "source": [
    "### Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5ec05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "df.hist()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2168b763",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "sns.countplot(x= df[\"target\"], palette=\"Set2\" )\n",
    "plt.title(\"Label Distribusion\", fontsize=26)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a56f720",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "sns.countplot(x= df[\"region\"], palette=\"Set2\" )\n",
    "plt.title(\"Region Distribusion\", fontsize=26)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c573bcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "sns.countplot(x= df[\"sex\"], palette=\"Set2\" )\n",
    "plt.title(\"Sex Distribusion\", fontsize=26)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d97b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "sns.countplot(x= df[\"cp\"], palette=\"Set2\" )\n",
    "plt.title(\"Cp Distribusion\", fontsize=26)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61238283",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "sns.countplot(x= df[\"slope\"], palette=\"Set2\" )\n",
    "plt.title(\"Slope Distribusion\", fontsize=26)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9472832b",
   "metadata": {},
   "source": [
    "### Bivariate & MultiVariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df0cbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 15))\n",
    "sns.boxplot(data=df[numerical_col], orient=\"h\")\n",
    "plt.title(\"Visualisasi Outlier pada Fitur Numerik\", fontsize=18)\n",
    "plt.yticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ed7fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "sns.scatterplot(x=df[\"trestbps\"], y=df[\"age\"])\n",
    "plt.title(\"Corelation Age and tresbps\", fontsize=26)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bacff21",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df = df.pivot_table(index='sex', columns='target', aggfunc='size', fill_value=0)\n",
    "\n",
    "pivot_df.plot(kind='bar', stacked=True, figsize=(10,6), colormap='Set2')\n",
    "plt.title(\"Perbandingan Penyakit Berdasarkan Jenis Kelamin\", fontsize=18)\n",
    "plt.xlabel(\"Jenis Kelamin\")\n",
    "plt.ylabel(\"Jumlah\")\n",
    "plt.legend(title=\"Target\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cf6231",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df = df.pivot_table(index='region', columns='target', aggfunc='size', fill_value=0)\n",
    "\n",
    "# ubah ke persentase\n",
    "pivot_df_percent = pivot_df.div(pivot_df.sum(axis=1), axis=0) * 100\n",
    "\n",
    "pivot_df_percent.plot(kind='bar', stacked=True, figsize=(12,6), colormap='coolwarm')\n",
    "plt.title(\"Proporsi (%) Penyakit per Region\", fontsize=18)\n",
    "plt.xlabel(\"Region\")\n",
    "plt.ylabel(\"Persentase (%)\")\n",
    "plt.legend(title=\"Target\", bbox_to_anchor=(1.05, 1))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515c7523",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df[numerical_col].corr()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\", cbar=True)\n",
    "plt.title(\"Correlation Matrix\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da52c538",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febd5df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_no_outlier = df.copy()\n",
    "\n",
    "\n",
    "# Loop tiap kolom numerik\n",
    "for col in df_no_outlier[numerical_col].columns:\n",
    "    Q1 = df_no_outlier[col].quantile(0.25)\n",
    "    Q3 = df_no_outlier[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "\n",
    "    # Filter data, hapus outlier\n",
    "    df_no_outlier = df_no_outlier[(df_no_outlier[col] >= lower) & (df_no_outlier[col] <= upper)]\n",
    "\n",
    "print(\"Shape sebelum:\", df.shape)\n",
    "print(\"Shape sesudah:\", df_no_outlier.shape)\n",
    "\n",
    "df_no_outlier.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab35b100",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df = df_no_outlier\n",
    "Scaler = MinMaxScaler()\n",
    "Scaler.fit(df_no_outlier[numerical_col])\n",
    "processed_df[numerical_col] = Scaler.transform(processed_df[numerical_col])\n",
    "joblib.dump(Scaler, \"./pkl/Scaler.pkl\")\n",
    "\n",
    "encoder = {}\n",
    "for col in categorical_col:\n",
    "    Encoder = LabelEncoder()\n",
    "    processed_df[col] = Encoder.fit_transform(processed_df[col])\n",
    "    encoder[col] = Encoder\n",
    "    joblib.dump(Encoder,  f\"./pkl/Le{col}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e443538a",
   "metadata": {},
   "outputs": [],
   "source": [
    "le_target = encoder[\"target\"]\n",
    "\n",
    "for original, encoded in zip(le_target.classes_, range(len(le_target.classes_))):\n",
    "    print(f\"{original} -> {encoded}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84649175",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9731aab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = processed_df.drop(columns=[\"target\",\"region\",\"index\"])\n",
    "y = processed_df[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bc5cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test, y_train, y_test = train_test_split(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54374226",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2211fa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_res.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2147474",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd970da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest\n",
    "rf = BalancedRandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=8,\n",
    "    bootstrap=False,\n",
    "    min_samples_split=8,\n",
    "    min_samples_leaf=4,\n",
    "    max_features='sqrt',\n",
    "    random_state=42\n",
    ")\n",
    "rf.fit(X_train_res, y_train_res)\n",
    "\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "knn = KNeighborsClassifier(\n",
    "    n_neighbors=3,   \n",
    "    weights='uniform',\n",
    "    metric='minkowski',\n",
    "    n_jobs=-1\n",
    ")\n",
    "knn.fit(X_train_res, y_train_res)\n",
    "\n",
    "\n",
    "\n",
    "# Logistic Regression\n",
    "log_reg = LogisticRegression(\n",
    "    solver='lbfgs',         \n",
    "    max_iter=1000,         \n",
    "    random_state=42,\n",
    "    class_weight='balanced'  \n",
    ")\n",
    "log_reg.fit(X_train_res, y_train_res)\n",
    "\n",
    "\n",
    "\n",
    "#  XGBoost Classifier\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=5,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='binary:logistic',  \n",
    "    eval_metric='logloss',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "xgb.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949feede",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.feature_names_in_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff2478e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, y_train, X_test, y_test, cv=5, scoring='f1_macro'):\n",
    "    \"\"\"\n",
    "    Evaluasi menyeluruh untuk model klasifikasi.\n",
    "    \n",
    "    Params:\n",
    "    - model: estimator (misal RandomForestClassifier)\n",
    "    - X_train, y_train: data latih (boleh hasil oversampling)\n",
    "    - X_test, y_test: data uji asli\n",
    "    - cv: jumlah fold cross-validation\n",
    "    - scoring: metric utama untuk cross_val_score\n",
    "    \n",
    "    Output:\n",
    "    - Plot learning curve\n",
    "    - Classification report & confusion matrix\n",
    "    - Cross-validation score\n",
    "    \"\"\"\n",
    "\n",
    "    # 1Ô∏è‚É£ Learning Curve\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        model, X_train, y_train, cv=cv, scoring='accuracy', n_jobs=-1\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(train_sizes, np.mean(train_scores, axis=1), label='Train', linewidth=2)\n",
    "    plt.plot(train_sizes, np.mean(test_scores, axis=1), label='Test', linewidth=2)\n",
    "    plt.xlabel(\"Training samples\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Learning Curve: Overfit Checker\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    plt.show()\n",
    "\n",
    "    # 2Ô∏è‚É£ Evaluation on Test Set\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"üîπ Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred, digits=3))\n",
    "    print(f\"‚úÖ Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"‚úÖ F1 Score (macro): {f1_score(y_test, y_pred, average='macro'):.4f}\")\n",
    "    print(f\"‚úÖ F1 Score (weighted): {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n",
    "\n",
    "    # 3Ô∏è‚É£ Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "    # 4Ô∏è‚É£ Cross-validation\n",
    "    acc_scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "    f1_scores = cross_val_score(model, X_train, y_train, cv=cv, scoring=scoring)\n",
    "\n",
    "    print(f\"\\nüîπ Cross-validation Results ({cv}-fold):\")\n",
    "    print(f\"   Mean Accuracy: {acc_scores.mean():.4f} ¬± {acc_scores.std():.4f}\")\n",
    "    print(f\"   Mean {scoring.upper()}: {f1_scores.mean():.4f} ¬± {f1_scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da20c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Random Forest model evaluation\")\n",
    "evaluate_model(\n",
    "    rf, \n",
    "    X_train_res, y_train_res,  \n",
    "    X_test, y_test,           \n",
    "    cv=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc758cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Knearest Neigtbors model evaluation\")\n",
    "evaluate_model(\n",
    "    knn, \n",
    "    X_train_res, y_train_res,  \n",
    "    X_test, y_test,           \n",
    "    cv=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0095db1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Logistic Regression model evaluation\")\n",
    "evaluate_model(\n",
    "    log_reg, \n",
    "    X_train_res, y_train_res,  \n",
    "    X_test, y_test,           \n",
    "    cv=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a4eca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Xgboost model evaluation\")\n",
    "evaluate_model(\n",
    "    xgb, \n",
    "    X_train_res, y_train_res,  \n",
    "    X_test, y_test,           \n",
    "    cv=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092dc980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- grid search untuk semua model ---\n",
    "def grid_search_all_models(models, param_grids, X_train, y_train, X_test, y_test):\n",
    "    best_models = {}\n",
    "    best_scores = {}\n",
    "\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nüîç Melakukan Grid Search untuk {name} ...\")\n",
    "        grid_search = GridSearchCV(\n",
    "            model, param_grids[name], cv=5, scoring=\"f1_weighted\", n_jobs=-1, verbose=2\n",
    "        )\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        print(f\"‚úÖ Best params untuk {name}: {grid_search.best_params_}\")\n",
    "        print(f\"‚úÖ Best F1 score (CV): {grid_search.best_score_:.4f}\")\n",
    "\n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_models[name] = best_model\n",
    "        best_scores[name] = grid_search.best_score_\n",
    "\n",
    "        # evaluasi di test set\n",
    "        print(f\"\\nüìä Evaluasi {name}\")\n",
    "        evaluate_model(best_model, X_train_res, y_train_res, X_test, y_test, cv=5)\n",
    "\n",
    "        # simpan best model\n",
    "        filename = f\"./best_model/best_model_{name}.joblib\"\n",
    "        joblib.dump(best_model, filename)\n",
    "        print(f\"üíæ Model terbaik {name} disimpan sebagai '{filename}'\")\n",
    "\n",
    "    # tampilkan model terbaik di antara semuanya\n",
    "    overall_best = max(best_scores, key=best_scores.get)\n",
    "    print(\"\\nüèÜ Model terbaik keseluruhan:\")\n",
    "    print(f\"{overall_best} dengan skor F1 (CV): {best_scores[overall_best]:.4f}\")\n",
    "    print(f\"Disimpan sebagai: best_model_{overall_best}.joblib\")\n",
    "\n",
    "    return best_models, best_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fe4c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "        \"RandomForest\": BalancedRandomForestClassifier(random_state=42),\n",
    "        \"KNN\": KNeighborsClassifier(),\n",
    "        \"LogisticRegression\": LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced'),\n",
    "        \"XGB\": XGBClassifier(objective='binary:logistic', eval_metric='logloss', random_state=42, n_jobs=-1)\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "        \"RandomForest\": {\n",
    "            'n_estimators': [200, 300, 400],\n",
    "            'max_depth': [6, 8, 10],\n",
    "            'bootstrap': [False],\n",
    "            'min_samples_split': [6, 8, 10],\n",
    "            'min_samples_leaf': [3, 4, 5],\n",
    "            'max_features': ['sqrt', 'log2']\n",
    "        },\n",
    "        \"KNN\": {\n",
    "            'n_neighbors': [3, 5, 7],\n",
    "            'weights': ['uniform', 'distance'],\n",
    "            'metric': ['minkowski', 'euclidean']\n",
    "        },\n",
    "        \"LogisticRegression\": {\n",
    "            'solver': ['lbfgs', 'liblinear'],\n",
    "            'C': [0.5, 1.0, 2.0]\n",
    "        },\n",
    "        \"XGB\": {\n",
    "            'n_estimators': [200, 300, 400],\n",
    "            'learning_rate': [0.03, 0.05, 0.1],\n",
    "            'max_depth': [4, 5, 6],\n",
    "            'subsample': [0.7, 0.8, 0.9],\n",
    "            'colsample_bytree': [0.7, 0.8, 0.9]\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "# jalankan grid search di semua model\n",
    "best_models, best_scores = grid_search_all_models(models, param_grids, X_train_res, y_train_res, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e4d90f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
